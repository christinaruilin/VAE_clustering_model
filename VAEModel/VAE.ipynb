{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f47c916",
   "metadata": {},
   "source": [
    "# VAE Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29408fcb",
   "metadata": {},
   "source": [
    "%pip install torch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a15e890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%pip install scipy scikit-learn matplotlib pandas anndata scanpy -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8ab40353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "# Step 1：import dependencies\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import mmread\n",
    "from scipy import sparse\n",
    "\n",
    "print('NumPy version:', np.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc7621a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final matrix: (15000, 307)\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "tfidf_sparse = sparse.load_npz('preprocessed_cutntag_final2.npz')\n",
    "cell_names = Path('filtered_cells_final2.txt').read_text().splitlines()\n",
    "peak_names = Path('filtered_peaks_final2.txt').read_text().splitlines()\n",
    "\n",
    "print('final matrix:', tfidf_sparse.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e01a750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7：define dataset wrapper\n",
    "class TfidfDataset(Dataset):\n",
    "    def __init__(self, matrix, log1p=True, zscore=False, l2_norm=True):\n",
    "        if sparse.issparse(matrix):\n",
    "            self.matrix = matrix.tocsc().astype(np.float32)\n",
    "        else:\n",
    "            self.matrix = sparse.csc_matrix(matrix, dtype=np.float32)\n",
    "        self.log1p = log1p\n",
    "        self.zscore = zscore\n",
    "        self.l2_norm = l2_norm\n",
    "\n",
    "        if self.zscore:\n",
    "            mean = np.asarray(self.matrix.mean(axis=1)).ravel().astype(np.float32)\n",
    "            sq_mean = np.asarray(self.matrix.power(2).mean(axis=1)).ravel().astype(np.float32)\n",
    "            var = np.clip(sq_mean - mean ** 2, a_min=1e-8, a_max=None)\n",
    "            self.feature_mean = mean\n",
    "            self.feature_std = np.sqrt(var)\n",
    "        else:\n",
    "            self.feature_mean = None\n",
    "            self.feature_std = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.matrix.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vec = self.matrix.getcol(idx).toarray().ravel()\n",
    "        if self.log1p:\n",
    "            vec = np.log1p(vec)\n",
    "        if self.zscore:\n",
    "            vec = (vec - self.feature_mean) / self.feature_std\n",
    "        if self.l2_norm:\n",
    "            norm = np.linalg.norm(vec)\n",
    "            if norm > 0:\n",
    "                vec = vec / norm\n",
    "        return torch.from_numpy(vec.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a9d66ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch shape: torch.Size([64, 15000])\n"
     ]
    }
   ],
   "source": [
    "# Step 8：load dataset and create DataLoader\n",
    "dataset_log1p = TfidfDataset(tfidf_sparse, log1p=True, zscore=False, l2_norm=True)\n",
    "train_fraction = 0.8\n",
    "num_cells = len(dataset_log1p)\n",
    "val_size = max(1, int(num_cells * (1 - train_fraction)))\n",
    "train_size = num_cells - val_size\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "    dataset_log1p, [train_size, val_size], generator=generator\n",
    ")\n",
    "\n",
    "batch_size = min(64, train_size)\n",
    "batch_size = max(batch_size, 16) \n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "example_batch = next(iter(train_loader))\n",
    "print('batch shape:', example_batch.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5b18670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9：define VAE model\n",
    "class SimpleVAE(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims=(256,64), latent_dim=16, dropout=0.2):\n",
    "        super().__init__()\n",
    "        enc_layers = []\n",
    "        last_dim = input_dim\n",
    "        for h in hidden_dims:\n",
    "            enc_layers += [torch.nn.Linear(last_dim, h), torch.nn.LayerNorm(h), torch.nn.ReLU(), torch.nn.Dropout(dropout)]\n",
    "            last_dim = h\n",
    "        self.encoder = torch.nn.Sequential(*enc_layers)\n",
    "        self.fc_mu = torch.nn.Linear(last_dim, latent_dim)\n",
    "        self.fc_logvar = torch.nn.Linear(last_dim, latent_dim)\n",
    "\n",
    "        dec_layers = []\n",
    "        last_dim = latent_dim\n",
    "        for h in reversed(hidden_dims):\n",
    "            dec_layers += [torch.nn.Linear(last_dim, h), torch.nn.LayerNorm(h), torch.nn.ReLU(), torch.nn.Dropout(dropout)]\n",
    "            last_dim = h\n",
    "        dec_layers += [torch.nn.Linear(last_dim, input_dim), torch.nn.Sigmoid()]\n",
    "        self.decoder = torch.nn.Sequential(*dec_layers)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decoder(z)\n",
    "        return recon, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9aea2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10：VAE loss function\n",
    "def vae_loss(recon_x, x, mu, logvar, beta):\n",
    "    recon_term = torch.nn.functional.mse_loss(recon_x, x, reduction='none')\n",
    "    recon_term = recon_term.mean(dim=1).mean()\n",
    "    kl_term = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_term + beta * kl_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "443888d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameter: 7732792\n",
      "learning rate: 1.0e-04, KL warmup: 30 epochs, beta_max: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Step 11：setting up the parameter\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_dim = tfidf_sparse.shape[0]\n",
    "model = SimpleVAE(input_dim=input_dim, hidden_dims=(256, 64), latent_dim=16, dropout=0.2).to(device)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-5 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "num_epochs = 200\n",
    "warmup_epochs = 30  # KL warmup \n",
    "beta_start = 0.0\n",
    "beta_max = 0.5  \n",
    "beta_increment = (beta_max - beta_start) / max(warmup_epochs, 1)\n",
    "beta = beta_start\n",
    "patience = 25\n",
    "best_state_path = 'vae_best.pt'\n",
    "\n",
    "print('Model parameter:', sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "print(f'learning rate: {learning_rate:.1e}, KL warmup: {warmup_epochs} epochs, beta_max: {beta_max}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "50122cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/200 | Train: 0.2534 | Val: 0.2446 | Beta: 0.00\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 002/200 | Train: 0.2474 | Val: 0.2371 | Beta: 0.02\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 003/200 | Train: 0.2377 | Val: 0.2278 | Beta: 0.03\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 004/200 | Train: 0.2287 | Val: 0.2185 | Beta: 0.05\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 005/200 | Train: 0.2199 | Val: 0.2092 | Beta: 0.07\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 006/200 | Train: 0.2118 | Val: 0.2005 | Beta: 0.08\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 007/200 | Train: 0.2033 | Val: 0.1919 | Beta: 0.10\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 008/200 | Train: 0.1950 | Val: 0.1835 | Beta: 0.12\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 009/200 | Train: 0.1876 | Val: 0.1758 | Beta: 0.13\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 010/200 | Train: 0.1799 | Val: 0.1681 | Beta: 0.15\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 011/200 | Train: 0.1726 | Val: 0.1606 | Beta: 0.17\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 012/200 | Train: 0.1658 | Val: 0.1531 | Beta: 0.18\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 013/200 | Train: 0.1589 | Val: 0.1459 | Beta: 0.20\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 014/200 | Train: 0.1520 | Val: 0.1397 | Beta: 0.22\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 015/200 | Train: 0.1458 | Val: 0.1327 | Beta: 0.23\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 016/200 | Train: 0.1397 | Val: 0.1263 | Beta: 0.25\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 017/200 | Train: 0.1339 | Val: 0.1207 | Beta: 0.27\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 018/200 | Train: 0.1275 | Val: 0.1147 | Beta: 0.28\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 019/200 | Train: 0.1222 | Val: 0.1088 | Beta: 0.30\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 020/200 | Train: 0.1169 | Val: 0.1037 | Beta: 0.32\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 021/200 | Train: 0.1113 | Val: 0.0987 | Beta: 0.33\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 022/200 | Train: 0.1064 | Val: 0.0935 | Beta: 0.35\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 023/200 | Train: 0.1020 | Val: 0.0890 | Beta: 0.37\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 024/200 | Train: 0.0974 | Val: 0.0845 | Beta: 0.38\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 025/200 | Train: 0.0928 | Val: 0.0803 | Beta: 0.40\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 026/200 | Train: 0.0895 | Val: 0.0761 | Beta: 0.42\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 027/200 | Train: 0.0854 | Val: 0.0730 | Beta: 0.43\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 028/200 | Train: 0.0807 | Val: 0.0686 | Beta: 0.45\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 029/200 | Train: 0.0778 | Val: 0.0653 | Beta: 0.47\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 030/200 | Train: 0.0736 | Val: 0.0614 | Beta: 0.48\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 031/200 | Train: 0.0702 | Val: 0.0591 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 032/200 | Train: 0.0678 | Val: 0.0555 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 033/200 | Train: 0.0639 | Val: 0.0527 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 034/200 | Train: 0.0608 | Val: 0.0501 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 035/200 | Train: 0.0586 | Val: 0.0471 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 036/200 | Train: 0.0559 | Val: 0.0450 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 037/200 | Train: 0.0533 | Val: 0.0431 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 038/200 | Train: 0.0508 | Val: 0.0409 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 039/200 | Train: 0.0487 | Val: 0.0387 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 040/200 | Train: 0.0466 | Val: 0.0366 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 041/200 | Train: 0.0453 | Val: 0.0349 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 042/200 | Train: 0.0426 | Val: 0.0332 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 043/200 | Train: 0.0410 | Val: 0.0315 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 044/200 | Train: 0.0391 | Val: 0.0301 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 045/200 | Train: 0.0373 | Val: 0.0285 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 046/200 | Train: 0.0355 | Val: 0.0271 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 047/200 | Train: 0.0343 | Val: 0.0259 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 048/200 | Train: 0.0329 | Val: 0.0248 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 049/200 | Train: 0.0311 | Val: 0.0233 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 050/200 | Train: 0.0304 | Val: 0.0225 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 051/200 | Train: 0.0288 | Val: 0.0216 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 052/200 | Train: 0.0278 | Val: 0.0208 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 053/200 | Train: 0.0270 | Val: 0.0198 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 054/200 | Train: 0.0257 | Val: 0.0187 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 055/200 | Train: 0.0252 | Val: 0.0182 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 056/200 | Train: 0.0236 | Val: 0.0174 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 057/200 | Train: 0.0231 | Val: 0.0168 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 058/200 | Train: 0.0228 | Val: 0.0159 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 059/200 | Train: 0.0222 | Val: 0.0158 | Beta: 0.50\n",
      "Epoch 060/200 | Train: 0.0216 | Val: 0.0148 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 061/200 | Train: 0.0201 | Val: 0.0142 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 062/200 | Train: 0.0198 | Val: 0.0138 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 063/200 | Train: 0.0188 | Val: 0.0131 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 064/200 | Train: 0.0186 | Val: 0.0127 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 065/200 | Train: 0.0181 | Val: 0.0122 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 066/200 | Train: 0.0175 | Val: 0.0118 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 067/200 | Train: 0.0166 | Val: 0.0114 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 068/200 | Train: 0.0164 | Val: 0.0110 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 069/200 | Train: 0.0160 | Val: 0.0105 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 070/200 | Train: 0.0153 | Val: 0.0104 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 071/200 | Train: 0.0151 | Val: 0.0097 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 072/200 | Train: 0.0145 | Val: 0.0095 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 073/200 | Train: 0.0144 | Val: 0.0092 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 074/200 | Train: 0.0140 | Val: 0.0091 | Beta: 0.50\n",
      "Epoch 075/200 | Train: 0.0136 | Val: 0.0087 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 076/200 | Train: 0.0135 | Val: 0.0085 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 077/200 | Train: 0.0128 | Val: 0.0082 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 078/200 | Train: 0.0124 | Val: 0.0081 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 079/200 | Train: 0.0122 | Val: 0.0077 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 080/200 | Train: 0.0122 | Val: 0.0074 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 081/200 | Train: 0.0119 | Val: 0.0074 | Beta: 0.50\n",
      "Epoch 082/200 | Train: 0.0113 | Val: 0.0071 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 083/200 | Train: 0.0114 | Val: 0.0071 | Beta: 0.50\n",
      "Epoch 084/200 | Train: 0.0109 | Val: 0.0068 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 085/200 | Train: 0.0105 | Val: 0.0067 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 086/200 | Train: 0.0107 | Val: 0.0065 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 087/200 | Train: 0.0101 | Val: 0.0063 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 088/200 | Train: 0.0100 | Val: 0.0062 | Beta: 0.50\n",
      "Epoch 089/200 | Train: 0.0099 | Val: 0.0061 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 090/200 | Train: 0.0095 | Val: 0.0058 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 091/200 | Train: 0.0094 | Val: 0.0057 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 092/200 | Train: 0.0091 | Val: 0.0055 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 093/200 | Train: 0.0089 | Val: 0.0054 | Beta: 0.50\n",
      "Epoch 094/200 | Train: 0.0090 | Val: 0.0053 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 095/200 | Train: 0.0088 | Val: 0.0052 | Beta: 0.50\n",
      "Epoch 096/200 | Train: 0.0085 | Val: 0.0051 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 097/200 | Train: 0.0081 | Val: 0.0049 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 098/200 | Train: 0.0081 | Val: 0.0049 | Beta: 0.50\n",
      "Epoch 099/200 | Train: 0.0081 | Val: 0.0048 | Beta: 0.50\n",
      "Epoch 100/200 | Train: 0.0077 | Val: 0.0046 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 101/200 | Train: 0.0079 | Val: 0.0046 | Beta: 0.50\n",
      "Epoch 102/200 | Train: 0.0077 | Val: 0.0044 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 103/200 | Train: 0.0075 | Val: 0.0044 | Beta: 0.50\n",
      "Epoch 104/200 | Train: 0.0073 | Val: 0.0043 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 105/200 | Train: 0.0074 | Val: 0.0042 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 106/200 | Train: 0.0071 | Val: 0.0041 | Beta: 0.50\n",
      "Epoch 107/200 | Train: 0.0069 | Val: 0.0040 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 108/200 | Train: 0.0068 | Val: 0.0040 | Beta: 0.50\n",
      "Epoch 109/200 | Train: 0.0067 | Val: 0.0038 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 110/200 | Train: 0.0067 | Val: 0.0038 | Beta: 0.50\n",
      "Epoch 111/200 | Train: 0.0066 | Val: 0.0037 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 112/200 | Train: 0.0066 | Val: 0.0037 | Beta: 0.50\n",
      "Epoch 113/200 | Train: 0.0065 | Val: 0.0036 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 114/200 | Train: 0.0063 | Val: 0.0035 | Beta: 0.50\n",
      "Epoch 115/200 | Train: 0.0062 | Val: 0.0035 | Beta: 0.50\n",
      "Epoch 116/200 | Train: 0.0060 | Val: 0.0034 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 117/200 | Train: 0.0059 | Val: 0.0033 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 118/200 | Train: 0.0060 | Val: 0.0033 | Beta: 0.50\n",
      "Epoch 119/200 | Train: 0.0058 | Val: 0.0033 | Beta: 0.50\n",
      "Epoch 120/200 | Train: 0.0057 | Val: 0.0032 | Beta: 0.50\n",
      "Epoch 121/200 | Train: 0.0057 | Val: 0.0033 | Beta: 0.50\n",
      "Epoch 122/200 | Train: 0.0057 | Val: 0.0032 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 123/200 | Train: 0.0055 | Val: 0.0031 | Beta: 0.50\n",
      "Epoch 124/200 | Train: 0.0054 | Val: 0.0030 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 125/200 | Train: 0.0053 | Val: 0.0030 | Beta: 0.50\n",
      "Epoch 126/200 | Train: 0.0053 | Val: 0.0029 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 127/200 | Train: 0.0052 | Val: 0.0029 | Beta: 0.50\n",
      "Epoch 128/200 | Train: 0.0052 | Val: 0.0029 | Beta: 0.50\n",
      "Epoch 129/200 | Train: 0.0052 | Val: 0.0028 | Beta: 0.50\n",
      "Epoch 130/200 | Train: 0.0051 | Val: 0.0027 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 131/200 | Train: 0.0049 | Val: 0.0028 | Beta: 0.50\n",
      "Epoch 132/200 | Train: 0.0050 | Val: 0.0027 | Beta: 0.50\n",
      "Epoch 133/200 | Train: 0.0049 | Val: 0.0027 | Beta: 0.50\n",
      "Epoch 134/200 | Train: 0.0048 | Val: 0.0026 | Beta: 0.50\n",
      "Epoch 135/200 | Train: 0.0048 | Val: 0.0026 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 136/200 | Train: 0.0048 | Val: 0.0026 | Beta: 0.50\n",
      "Epoch 137/200 | Train: 0.0046 | Val: 0.0026 | Beta: 0.50\n",
      "Epoch 138/200 | Train: 0.0046 | Val: 0.0025 | Beta: 0.50\n",
      "Epoch 139/200 | Train: 0.0045 | Val: 0.0025 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 140/200 | Train: 0.0044 | Val: 0.0025 | Beta: 0.50\n",
      "Epoch 141/200 | Train: 0.0045 | Val: 0.0024 | Beta: 0.50\n",
      "Epoch 142/200 | Train: 0.0043 | Val: 0.0024 | Beta: 0.50\n",
      "Epoch 143/200 | Train: 0.0044 | Val: 0.0024 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 144/200 | Train: 0.0043 | Val: 0.0024 | Beta: 0.50\n",
      "Epoch 145/200 | Train: 0.0042 | Val: 0.0023 | Beta: 0.50\n",
      "Epoch 146/200 | Train: 0.0043 | Val: 0.0023 | Beta: 0.50\n",
      "Epoch 147/200 | Train: 0.0041 | Val: 0.0023 | Beta: 0.50\n",
      "Epoch 148/200 | Train: 0.0040 | Val: 0.0023 | Beta: 0.50\n",
      "Epoch 149/200 | Train: 0.0041 | Val: 0.0023 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 150/200 | Train: 0.0040 | Val: 0.0022 | Beta: 0.50\n",
      "Epoch 151/200 | Train: 0.0040 | Val: 0.0022 | Beta: 0.50\n",
      "Epoch 152/200 | Train: 0.0041 | Val: 0.0022 | Beta: 0.50\n",
      "Epoch 153/200 | Train: 0.0040 | Val: 0.0022 | Beta: 0.50\n",
      "Epoch 154/200 | Train: 0.0039 | Val: 0.0021 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 155/200 | Train: 0.0039 | Val: 0.0021 | Beta: 0.50\n",
      "Epoch 156/200 | Train: 0.0038 | Val: 0.0021 | Beta: 0.50\n",
      "Epoch 157/200 | Train: 0.0039 | Val: 0.0021 | Beta: 0.50\n",
      "Epoch 158/200 | Train: 0.0036 | Val: 0.0021 | Beta: 0.50\n",
      "Epoch 159/200 | Train: 0.0036 | Val: 0.0020 | Beta: 0.50\n",
      "Epoch 160/200 | Train: 0.0036 | Val: 0.0020 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 161/200 | Train: 0.0036 | Val: 0.0020 | Beta: 0.50\n",
      "Epoch 162/200 | Train: 0.0036 | Val: 0.0020 | Beta: 0.50\n",
      "Epoch 163/200 | Train: 0.0036 | Val: 0.0019 | Beta: 0.50\n",
      "Epoch 164/200 | Train: 0.0035 | Val: 0.0019 | Beta: 0.50\n",
      "Epoch 165/200 | Train: 0.0036 | Val: 0.0019 | Beta: 0.50\n",
      "Epoch 166/200 | Train: 0.0035 | Val: 0.0019 | Beta: 0.50\n",
      "Epoch 167/200 | Train: 0.0034 | Val: 0.0019 | Beta: 0.50\n",
      "Epoch 168/200 | Train: 0.0035 | Val: 0.0019 | Beta: 0.50\n",
      "Epoch 169/200 | Train: 0.0034 | Val: 0.0019 | Beta: 0.50\n",
      "Epoch 170/200 | Train: 0.0034 | Val: 0.0018 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 171/200 | Train: 0.0034 | Val: 0.0018 | Beta: 0.50\n",
      "Epoch 172/200 | Train: 0.0032 | Val: 0.0018 | Beta: 0.50\n",
      "Epoch 173/200 | Train: 0.0033 | Val: 0.0018 | Beta: 0.50\n",
      "Epoch 174/200 | Train: 0.0033 | Val: 0.0018 | Beta: 0.50\n",
      "Epoch 175/200 | Train: 0.0032 | Val: 0.0017 | Beta: 0.50\n",
      "Epoch 176/200 | Train: 0.0031 | Val: 0.0018 | Beta: 0.50\n",
      "Epoch 177/200 | Train: 0.0032 | Val: 0.0017 | Beta: 0.50\n",
      "Epoch 178/200 | Train: 0.0033 | Val: 0.0018 | Beta: 0.50\n",
      "Epoch 179/200 | Train: 0.0032 | Val: 0.0017 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 180/200 | Train: 0.0031 | Val: 0.0017 | Beta: 0.50\n",
      "Epoch 181/200 | Train: 0.0032 | Val: 0.0017 | Beta: 0.50\n",
      "Epoch 182/200 | Train: 0.0031 | Val: 0.0017 | Beta: 0.50\n",
      "Epoch 183/200 | Train: 0.0031 | Val: 0.0017 | Beta: 0.50\n",
      "Epoch 184/200 | Train: 0.0032 | Val: 0.0017 | Beta: 0.50\n",
      "Epoch 185/200 | Train: 0.0030 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 186/200 | Train: 0.0030 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 187/200 | Train: 0.0029 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 188/200 | Train: 0.0030 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 189/200 | Train: 0.0030 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 190/200 | Train: 0.0029 | Val: 0.0016 | Beta: 0.50\n",
      "  -> new best model save as vae_best.pt\n",
      "Epoch 191/200 | Train: 0.0030 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 192/200 | Train: 0.0029 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 193/200 | Train: 0.0028 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 194/200 | Train: 0.0029 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 195/200 | Train: 0.0028 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 196/200 | Train: 0.0029 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 197/200 | Train: 0.0029 | Val: 0.0016 | Beta: 0.50\n",
      "Epoch 198/200 | Train: 0.0027 | Val: 0.0015 | Beta: 0.50\n",
      "Epoch 199/200 | Train: 0.0028 | Val: 0.0015 | Beta: 0.50\n",
      "Epoch 200/200 | Train: 0.0028 | Val: 0.0015 | Beta: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Step 12：training loop with KL warmup and early stopping\n",
    "best_val = float('inf')\n",
    "best_epoch = 0\n",
    "epochs_since_improve = 0\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon, mu, logvar = model(batch)\n",
    "        loss = vae_loss(recon, batch, mu, logvar, beta=beta)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            recon, mu, logvar = model(batch)\n",
    "            val_loss = vae_loss(recon, batch, mu, logvar, beta=beta)\n",
    "            val_losses.append(val_loss.item())\n",
    "\n",
    "    train_loss = float(np.mean(train_losses))\n",
    "    val_loss = float(np.mean(val_losses))\n",
    "    print(f'Epoch {epoch:03d}/{num_epochs} | Train: {train_loss:.4f} | Val: {val_loss:.4f} | Beta: {beta:.2f}')\n",
    "\n",
    "    if val_loss < best_val - 1e-4:\n",
    "        best_val = val_loss\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), best_state_path)\n",
    "        epochs_since_improve = 0\n",
    "        print(f'  -> new best model save as {best_state_path}')\n",
    "    else:\n",
    "        epochs_since_improve += 1\n",
    "        if epochs_since_improve >= patience:\n",
    "            print(f'early stop best epoch {best_epoch:03d}，Val Loss {best_val:.4f}')\n",
    "            break\n",
    "\n",
    "    if epoch <= warmup_epochs:\n",
    "        beta = min(beta_max, beta + beta_increment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae09f287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent shape: (307, 16)\n",
      "saved vae_latent_new1.csv and vae_latent_new1.npy\n"
     ]
    }
   ],
   "source": [
    "# Step 13：load best model and extract latent representations\n",
    "model.load_state_dict(torch.load(best_state_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "inference_batch_size = batch_size \n",
    "full_loader = DataLoader(dataset_log1p, batch_size=inference_batch_size, shuffle=False)\n",
    "latents = []\n",
    "with torch.no_grad():\n",
    "    for batch in full_loader:\n",
    "        batch = batch.to(device)\n",
    "        mu, _ = model.encode(batch)\n",
    "        latents.append(mu.cpu().numpy())\n",
    "\n",
    "latent_array = np.vstack(latents)\n",
    "print('latent shape:', latent_array.shape)\n",
    "\n",
    "latent_df = pd.DataFrame(latent_array, index=cell_names[: latent_array.shape[0]])\n",
    "latent_df.to_csv('vae_latent_new1.csv')\n",
    "np.save('vae_latent_new1.npy', latent_array)\n",
    "print('saved vae_latent_new1.csv and vae_latent_new1.npy')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
